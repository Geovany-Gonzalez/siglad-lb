# === NGINX como Balanceador L7 para dos backends en Render ===
# - Round-robin 50/50 (split_clients)
# - Reintento automático si el primero falla (red/timeout/5xx)
# - TLS SNI correcto hacia cada backend
# - Headers X-* para ver quién respondió, código y tiempos
# - Endpoints de diagnóstico: /_lb/health, /_lb/which, /_lb/status
# - Logs en stdout con tiempos y upstream (para ver en Render Logs)

worker_processes auto;
# Lleva logs a la consola del contenedor (Render los captura)
error_log  /dev/stderr notice;
pid        off;

events { worker_connections 1024; }

http {
  # -------- Logging bonito con upstream y tiempos --------
  log_format main
    '$remote_addr - $remote_user [$time_local] "$request" $status $body_bytes_sent '
    '"$http_referer" "$http_user_agent" '
    'rt=$request_time urt=$upstream_response_time ustatus=$upstream_status '
    'uaddr=$upstream_addr uhost=$host';

  access_log /dev/stdout main;

  # Tipos mime básicos
  include       mime.types;
  default_type  application/octet-stream;

  # Resolver público (necesario porque los backends son hostnames *.onrender.com)
  resolver 1.1.1.1 1.0.0.1 valid=300s ipv6=off;

  # -------- Balanceo 50/50 --------
  # Usamos una "semilla" por request (IP+método+path) para repartir.
  # Si querés 70/30: cambias el 50% por 70%.
  split_clients "${remote_addr}${request_method}${request_uri}" $backend_host {
    50%     "siglad-proyecto.onrender.com";
    *       "siglad-proyectoii.onrender.com";
  }

  # Host header correcto que enviaremos al origen
  map $backend_host $host_hdr {
    default $backend_host;
  }

  server {
    # Render te hablará al puerto indicado por la env PORT (nosotros escuchamos en 8080)
    listen 8080;

    # --------- Headers de diagnóstico en TODAS las respuestas ---------
    add_header X-LB              "siglad-nginx"            always;
    add_header X-Upstream-Host   $backend_host             always; # hostname elegido
    add_header X-Upstream-Addr   $upstream_addr            always; # ip:puerto real
    add_header X-Upstream-Status $upstream_status          always; # código del upstream
    add_header X-Upstream-Time   $upstream_response_time   always; # tiempo del upstream

    # --------- Endpoints de diagnóstico ---------
    # Salud del balanceador (no toca a los backends)
    location = /_lb/health {
      add_header Content-Type text/plain;
      return 200 "ok\n";
    }

    # ¿Qué backend se eligió PARA ESTA request? (útil para demos)
    location = /_lb/which {
      add_header Content-Type text/plain;
      return 200 "$backend_host\n";
    }

    # Estado interno de NGINX (conexiones, etc.)
    location = /_lb/status {
      stub_status;  # Built-in module
      access_log off;
    }

    # --------- Proxy principal ---------
    location / {
      # Pasar al backend elegido
      proxy_pass https://$backend_host;

      # Encabezados habituales
      proxy_set_header Host $host_hdr;
      proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
      proxy_set_header X-Forwarded-Host  $host;

      # TLS hacia el origen (Render): habilita SNI y usa el nombre del backend
      proxy_ssl_server_name on;
      proxy_ssl_name        $backend_host;

      # Reintentos de upstream cuando el primero falla
      proxy_next_upstream        error timeout http_500 http_502 http_503 http_504;
      proxy_next_upstream_tries  2;     # intenta como máx. 1 vez el segundo backend

      # Timeouts razonables (ajustá si tus backends "despiertan" lento en plan Free)
      proxy_connect_timeout  5s;   # handshake TCP/TLS
      proxy_read_timeout     30s;  # esperar respuesta del backend
      proxy_send_timeout     30s;  # enviar request al backend
    }
  }
}
