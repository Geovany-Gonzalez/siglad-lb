# ========= Básicos =========
worker_processes 1;

events { worker_connections 1024; }

http {
  # DNS para resolver los hosts de Render en tiempo de ejecución
  resolver 1.1.1.1 1.0.0.1 ipv6=off valid=300s;

  # Log en JSON simple (verás "uback" con el backend elegido)
  log_format lb_json escape=json
    '{ "ts":"$time_iso8601", "remote_addr":"$remote_addr", '
    '"method":"$request_method", "uri":"$uri", "protocol":"$server_protocol", '
    '"status":"$status","bytes":"$body_bytes_sent", '
    '"host":"$host","uback":"$target","uaddr":"$upstream_addr",'
    '"rt":"$request_time","urt":"$upstream_response_time","rid":"$request_id" }';

  access_log /dev/stdout lb_json;
  error_log  /dev/stderr warn;

  # ========= Balanceo 50/50 =========
  #
  # split_clients crea una variable $target con distribución 50/50
  # (usa remote_addr + request_id para “mezclar” bien)
  split_clients "${remote_addr}${request_id}" $target {
    50%  "siglad-proyecto.onrender.com";
    50%  "siglad-proyectoii.onrender.com";
  }

  # Si quieres forzar temporalmente TODO al “II”, comenta el split de arriba
  # y descomenta esta línea:
  # map "" $target { default "siglad-proyectoii.onrender.com"; }

  # ========= Servidor público =========
  server {
    listen 8080;
    server_name _;

    # --- endpoint de health del LB ---
    location = /_lb/health {
      add_header Content-Type application/json;
      return 200 '{"ok":true}';
    }

    # --- ¿a qué backend se envió esta petición? ---
    # (útil para probar el reparto; debe alternar entre los dos)
    location = /_lb/which {
      default_type text/plain;
      return 200 "$target\n";
    }

    # --- proxy principal (SPA/estático) ---
    location / {
      # SNI/Host correctos para TLS en Render
      proxy_ssl_server_name on;
      proxy_ssl_name $target;
      proxy_set_header Host $target;

      # Encabezados estándar
      proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
      proxy_set_header X-Request-ID $request_id;

      # Reintentos y tolerancia a fallas
      proxy_next_upstream error timeout http_502 http_503 http_504;
      proxy_next_upstream_tries 2;

      # Cacheo de errores cortos para no martillar un upstream caído
      proxy_cache_bypass $http_pragma;
      proxy_intercept_errors off;

      # Pasa al upstream HTTPS elegido
      proxy_pass https://$target;
    }
  }
}
